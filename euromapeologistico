import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# Cargamos los datos
data = pd.read_csv('data.csv')

# Preprocesamos los datos
scaler = MinMaxScaler()
X = scaler.fit_transform(data.drop(['label'], axis=1))
y = scaler.inverse_transform(data['label'])

# Splitimos los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definimos el modelo
model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='linear'))

# Configuramos el modelo
model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001), metrics=['mae'])

# Entrenamos el modelo
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))

# Analizamos la sensibilidad
sensitivity_analysis = history.history['mae']

# Generamos el bloque de 5 números
block = np.random.randint(1, 50, size=5)

# Aplicamos el mapeo logístico
logistic_map = np.zeros((len(block), 1))
for i in range(len(block)):
    logistic_map[i] = np.log(block[i]) / (1 + np.exp(-np.log(block[i])))

# Aplicamos el análisis de sensibilidad
sensitivity_scores = np.zeros((len(block), 1))
for i in range(len(block)):
    sensitivity_scores[i] = sensitivity_analysis[i] * logistic_map[i]

# Combinamos los resultados
result = np.concatenate((block, sensitivity_scores), axis=1)

# Mostramos los resultados
print('Bloque de 5 números generado:', result)
